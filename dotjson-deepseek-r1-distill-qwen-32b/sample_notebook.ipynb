{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying dotjson - Deepseek-R1-Distill-Qwen-32B with structured outputs from AWS Marketplace \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This sample notebook shows you how to deploy [dotjson - Deepseek-R1-Distill-Qwen-32B with structured outputs](https://aws.amazon.com/marketplace/pp/prodview-mb7desoblqh2w) using Amazon SageMaker.\n",
    "\n",
    "Make your AI-powered applications reliable with our structured outputs solution for DeepSeek-R1-Distill-Qwen-32B. This fully managed service seamlessly integrates with your AWS infrastructure, delivering guaranteed JSON Schema-compliant outputs directly from the language model. Simply deploy through AWS Marketplace, and receive valid JSON responses every time. Our solution leverages proprietary optimization technology designed specifically for AWS environments, ensuring zero-latency structured outputs. Unlike traditional LLM implementations that require complex post-processing and development overhead, our service dramatically increases schema compliance while maintaining the model's full performance. Transform unreliable AI outputs into production-ready, structured data without sacrificing speed or accuracy.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "\n",
    "## Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Subscribe to the model package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the model package:\n",
    "1. Open the model package listing page [dotjson - Deepseek-R1-Distill-Qwen-32B with structured outputs](https://aws.amazon.com/marketplace/pp/prodview-mb7desoblqh2w) \n",
    "1. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3. Copy the ARN corresponding to your region and specify the same in the following cell.\n",
    "2. Choose or create an execution role that has the **AmazonSageMakerFullAccess** IAM policy attached. If it already exists, the execution role can be found below the **Product Arn** on the configuration page. Otherwise, go to the **IAM** console on AWS to create a role with Sagemaker execution access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_arn = (\n",
    "    \"<Customer to specify Model package ARN corresponding to their AWS region>\"\n",
    ")\n",
    "\n",
    "\n",
    "execution_role = \"<Customer to specify Model package ARN with AmazonSageMakerFullAccess IAM policy attached>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session(boto_session=session)\n",
    "sagemaker_client = sagemaker_session.sagemaker_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create an endpoint and perform real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to understand how real-time inference with Amazon SageMaker works, see [Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html).\n",
    "\n",
    "**Define the endpoint configuration:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"dotjson-with-DeepSeek-R1-Distill-Qwen-32B\"\n",
    "content_type = \"application/json\"\n",
    "inference_instance_type = \"ml.g6e.12xlarge\"\n",
    "endpoint_config_name = f\"{model_name}-config\"\n",
    "endpoint_name = f\"{model_name}-notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy a model on sagemaker using the model package arn \n",
    "create_model_response = sagemaker_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    PrimaryContainer={\"ModelPackageName\": model_package_arn},\n",
    "    ExecutionRoleArn=execution_role,\n",
    "    EnableNetworkIsolation=True,\n",
    ")\n",
    "\n",
    "# Create endpoint configuration\n",
    "endpoint_config_name = f\"{model_name}-config\"\n",
    "create_endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": inference_instance_type,\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])\n",
    "\n",
    "# Create endpoint\n",
    "sagemaker_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once endpoint has been created, you would be able to perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Create input payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"payload.json\", \"r\") as f:\n",
    "    payload = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the endpoint and extract the response body\n",
    "runtime = session.client(\"sagemaker-runtime\")\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name\",\n",
    "    ContentType=content_type,\n",
    "    Accept=content_type,\n",
    "    Body=payload,\n",
    ")\n",
    "body = json.loads(response[\"Body\"].read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model response to out file\n",
    "output_file_name = \"character.json\"\n",
    "with open(output_file_name, \"w\") as outfile:\n",
    "    json.dump(body, outfile, indent=4)\n",
    "\n",
    "# View the structured output produced by the model\n",
    "msg = body[\"choices\"][0][\"message\"]\n",
    "content = msg[\"content\"]\n",
    "character = json.loads(content)\n",
    "character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean-up\n",
    "\n",
    "### A. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate the endpoint to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sagemaker_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client.delete_model(ModelName=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the model package, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
